{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "1e120292-4bb7-4eed-94cf-eb1640bbf2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from tqdm import tqdm, trange\n",
    "import gensim.downloader\n",
    "from gensim.models import Word2Vec\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split \n",
    "import re\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "8ccd756f-8a02-46d8-ba92-746ca503e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "  # Characterizes a dataset for PyTorch\n",
    "  def __init__(self, list_IDs, labels):\n",
    "        'Initialization'\n",
    "        self.labels = labels\n",
    "        self.list_IDs = list_IDs\n",
    "\n",
    "  def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.list_IDs)\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        \n",
    "        X = self.list_IDs[index]\n",
    "        y = self.labels[index]\n",
    "\n",
    "        return X.float(), y.float()\n",
    "    \n",
    "def predict(dataloader, model):\n",
    "    model.eval()\n",
    "    predictions = np.array([])\n",
    "    for x_batch, _ in dataloader:\n",
    "        \n",
    "        preds = model(x_batch)\n",
    "        predictions = np.hstack((predictions, preds.detach().numpy().flatten()))\n",
    "    return predictions.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "de444a2f-655b-4a20-ad45-a87d26ad462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "d457212e-8594-4a5a-a197-0bb95bf6d857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fuck you you self righteous creep</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>stop stop the goddam vandalism or there ll be...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i agree rt does have a few shortcomings  but i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you would like verfiability here is the lin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>do you think there s consensus for me to be on...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34642</th>\n",
       "      <td>huy i am kyle robbins i think albert pujols is...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34643</th>\n",
       "      <td>unlike the ancient greeks  the idiot who  bloc...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34644</th>\n",
       "      <td>no it isn t  so if you wish to delete my accou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34645</th>\n",
       "      <td>you haven t been paying attention  i don t c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34646</th>\n",
       "      <td>you are the racist piece of dirt buckley  and...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34647 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comment_text  toxicity\n",
       "id                                                                \n",
       "0                     fuck you you self righteous creep          3\n",
       "1       stop stop the goddam vandalism or there ll be...         2\n",
       "2      i agree rt does have a few shortcomings  but i...         0\n",
       "3      if you would like verfiability here is the lin...         0\n",
       "4      do you think there s consensus for me to be on...         0\n",
       "...                                                  ...       ...\n",
       "34642  huy i am kyle robbins i think albert pujols is...         4\n",
       "34643  unlike the ancient greeks  the idiot who  bloc...         4\n",
       "34644  no it isn t  so if you wish to delete my accou...         1\n",
       "34645    you haven t been paying attention  i don t c...         1\n",
       "34646   you are the racist piece of dirt buckley  and...         3\n",
       "\n",
       "[34647 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"sentiment.csv\", index_col=\"id\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ef0cfd1a-59e3-4c08-8a0a-b80184881093",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.62501803907986"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(str(df[\"comment_text\"][i]).split()) for i in range(0, len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "390af349-3b2c-44b0-96f3-edcc40eccdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preporation_and_corpus(data: np.array, max_legth: int):\n",
    "    data_prepeared = []\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    for index in trange(0, len(data)):\n",
    "        line = data[index]\n",
    "        line = str(line)\n",
    "        line = line.lower()\n",
    "        splited = re.split(\" \", line)\n",
    "        splited = np.array([i for i in splited if (i not in stop_words) and (i not in '')])\n",
    "        for element in range(0, len(splited)):\n",
    "            splited[element] = lemmatizer.lemmatize(splited[element])\n",
    "        \n",
    "        data_prepeared.append(splited)\n",
    "        \n",
    "    data_prepeared_pd = pd.DataFrame(data_prepeared)\n",
    "    data_prepeared_pd.fillna('@None', inplace=True)\n",
    "    data_prepeared_pd = data_prepeared_pd.iloc[:, :max_legth]\n",
    "    data_prepeared_pd = data_prepeared_pd.to_numpy()\n",
    "    return data_prepeared_pd\n",
    " \n",
    "def word2vec_tranform(data, model):\n",
    "    data_null = np.zeros((data.shape[0], data.shape[1], 100))\n",
    "    \n",
    "    for column in trange(0, data.shape[0]):\n",
    "        for index in range(0, data.shape[1]):\n",
    "            try: word_embedding = model.get_vector(data[column][index])\n",
    "            except: word_embedding = model.get_vector('@None')\n",
    "            for element in range(0, word_embedding.shape[0]):\n",
    "                \n",
    "                data_null[column][index][element] = word_embedding[element]  \n",
    "\n",
    "    return data_null\n",
    "\n",
    "def to_torch_transformation(data:np.array):\n",
    "    data = torch.from_numpy(data)\n",
    "    return data\n",
    "    \n",
    "def create_vocab(data):\n",
    "    main = []\n",
    "    for line in data:\n",
    "        main.append(line.tolist())\n",
    "        \n",
    "    return list(set(list(itertools.chain.from_iterable(main))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5abecb61-5f24-47e3-acb7-bad9d342a949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 34647/34647 [00:03<00:00, 10276.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['fuck', 'self', 'righteous', ..., '@None', '@None', '@None'],\n",
       "       ['stop', 'stop', 'goddam', ..., '@None', '@None', '@None'],\n",
       "       ['agree', 'rt', 'shortcoming', ..., 'choice', 'avoiding',\n",
       "        'nonsense'],\n",
       "       ...,\n",
       "       ['wish', 'delete', 'account', ..., '@None', '@None', '@None'],\n",
       "       ['paying', 'attention', 'compromise', ..., '@None', '@None',\n",
       "        '@None'],\n",
       "       ['racist', 'piece', 'dirt', ..., '@None', '@None', '@None']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prepeared = data_preporation_and_corpus(df['comment_text'].to_numpy(), 60)\n",
    "data_prepeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "79a415a2-338a-45f6-a90b-0a85362c3b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = create_vocab(data_prepeared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "86c21301-2a14-44a2-ab40-11eacf928970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_vectors = gensim.downloader.load('glove-twitter-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "7c220cf1-917b-46e0-a77d-f3d0c5e275ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(sentences=data_prepeared.tolist(),\n",
    "                     min_count=1,\n",
    "                     window=4,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "03ab767c-471f-4a3d-ac0d-9fe31c07e608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 59.4 s, sys: 329 ms, total: 59.8 s\n",
      "Wall time: 20.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(17146716, 62364600)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "w2v_model.train(data_prepeared.tolist(), total_examples=len(vocab), epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8541ec65-733f-46b1-a361-5310c988a65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 34647/34647 [00:52<00:00, 656.43it/s]\n"
     ]
    }
   ],
   "source": [
    "data_prepeared_embedded = word2vec_tranform(data_prepeared, w2v_model.wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "08a96a2c-e7ba-438a-bf29-94cc340c0336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34647, 60, 100)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_prepeared_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b82f698b-c69e-4ea3-b91f-86a89025ea60",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prepeared_embedded = np.swapaxes(data_prepeared_embedded, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ebdfee66-bdbc-4d18-9d13-f7e0d79672ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(data_prepeared_embedded, df['toxicity'], test_size=0.0001, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f4ffe222-69fc-401c-bdca-bf506a82b8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = to_torch_transformation(X_train)\n",
    "X_val = to_torch_transformation(X_val)\n",
    "y_train = to_torch_transformation(y_train.to_numpy())\n",
    "y_val = to_torch_transformation(y_val.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "367906aa-3617-4fe5-8a08-8846e294e1b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34643, 100, 60])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "998df233-5e8f-4ec9-8abf-33258ce0e818",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset(X_train, y_train)\n",
    "val_set = Dataset(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90924bb7-511a-46ba-a2da-421fdf2da447",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_generator = DataLoader(training_set, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bc62eefd-798d-4365-84ef-67625aeba358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN1D(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv_1 = nn.Conv1d(100, 200, 3, stride=1)\n",
    "        self.conv_2 = nn.Conv1d(200, 400, 3, stride=1)\n",
    "        self.conv_3 = nn.Conv1d(400, 800, 3, stride=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(800, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 64)\n",
    "        self.fc4 = nn.Linear(64, 6)\n",
    "        \n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.soft = nn.Softmax()\n",
    "        self.max_pool = nn.AvgPool1d(3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.max_pool(self.relu(self.conv_1(x)))\n",
    "        x = self.max_pool(self.relu(self.conv_2(x)))\n",
    "        x = self.max_pool(self.relu(self.conv_3(x))).flatten(start_dim=1)\n",
    "\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = self.soft(x)\n",
    "        \n",
    "        return x.float()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "28af5a44-5ebd-4bda-9d47-d28becbe5d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN1D()\n",
    "\n",
    "lr = 0.0001\n",
    "EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e4c17894-1444-4dad-9f83-b880fd821d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2026e10e-8095-41f8-9262-6e1ee8815866",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/dc92r6ps4_q25drxrf_7btlm0000gn/T/ipykernel_3509/2252360471.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.soft(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.805\n",
      "[1,   200] loss: 0.788\n",
      "[1,   300] loss: 0.786\n",
      "[1,   400] loss: 0.788\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pd/dc92r6ps4_q25drxrf_7btlm0000gn/T/ipykernel_3509/1064772706.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/pd/dc92r6ps4_q25drxrf_7btlm0000gn/T/ipykernel_3509/2252360471.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/mambaforge/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    307\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 309\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    310\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for step, (x, y) in enumerate(train_generator):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "\n",
    "        loss = criterion(outputs, y.type(torch.LongTensor))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        if step % 100 == 99:   \n",
    "            print(f'[{epoch + 1}, {step + 1:5d}] loss: {running_loss / 200:.3f}')\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "93467b4a-3f31-4dc9-8b8d-d79ee48a22f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/dc92r6ps4_q25drxrf_7btlm0000gn/T/ipykernel_3509/1242343704.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.soft(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(X_val.float())\n",
    "output = torch.argmax(output, dim=1)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4b665428-e086-4879-8681-22748c94d7da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(output.numpy(), y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a2e3d46d-1e2e-4996-aba6-5117c57a0c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34647</th>\n",
       "      <td>oh that great repository of free cultural work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34648</th>\n",
       "      <td>my rfa  with apologies for the impersonal awb ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34649</th>\n",
       "      <td>it looks like a number of articles you created...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34650</th>\n",
       "      <td>oh  but i see you ve been  block  for other  s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34651</th>\n",
       "      <td>accord of the discussion in mariah carey compo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43836</th>\n",
       "      <td>atat  rk you cannot escape atat  rk s racial s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43837</th>\n",
       "      <td>irresponsible dumheads  each and every image h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43838</th>\n",
       "      <td>i agrre with above and i checked and in shia s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43839</th>\n",
       "      <td>i think there should be some form of screening...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43840</th>\n",
       "      <td>i  suck ed as an admin anyway</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9194 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comment_text\n",
       "id                                                      \n",
       "34647  oh that great repository of free cultural work...\n",
       "34648  my rfa  with apologies for the impersonal awb ...\n",
       "34649  it looks like a number of articles you created...\n",
       "34650  oh  but i see you ve been  block  for other  s...\n",
       "34651  accord of the discussion in mariah carey compo...\n",
       "...                                                  ...\n",
       "43836  atat  rk you cannot escape atat  rk s racial s...\n",
       "43837  irresponsible dumheads  each and every image h...\n",
       "43838  i agrre with above and i checked and in shia s...\n",
       "43839  i think there should be some form of screening...\n",
       "43840                      i  suck ed as an admin anyway\n",
       "\n",
       "[9194 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv(\"test.csv\", index_col=\"id\")\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4c8446c1-b933-43f3-8bc7-af33d236dfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████| 9194/9194 [00:00<00:00, 12438.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['oh', 'great', 'repository', ..., '@None', '@None', '@None'],\n",
       "       ['rfa', 'apology', 'impersonal', ..., 'categorize', 'also',\n",
       "        'successfully'],\n",
       "       ['look', 'like', 'number', ..., '@None', '@None', '@None'],\n",
       "       ...,\n",
       "       ['agrre', 'checked', 'shia', ..., '@None', '@None', '@None'],\n",
       "       ['think', 'form', 'screening', ..., '@None', '@None', '@None'],\n",
       "       ['suck', 'ed', 'admin', ..., '@None', '@None', '@None']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prepeared = data_preporation_and_corpus(df_test['comment_text'].to_numpy(), 60)\n",
    "test_prepeared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5977cbdd-c725-450b-becb-6d53b0c536a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 9194/9194 [00:13<00:00, 656.86it/s]\n"
     ]
    }
   ],
   "source": [
    "data_test_embedded = word2vec_tranform(test_prepeared, w2v_model.wv)\n",
    "data_test_embedded = np.swapaxes(data_test_embedded, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "376878c2-3be4-4e7a-b967-8a9a82278682",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = to_torch_transformation(data_test_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8f49ba57-b169-4ea6-aab9-5b8e2c2e69c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pd/dc92r6ps4_q25drxrf_7btlm0000gn/T/ipykernel_3509/1242343704.py:30: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = self.soft(x)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0,  ..., 1, 1, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_test = model(X_test.float())\n",
    "output_test = torch.argmax(output_test, dim=1)\n",
    "output_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ace642e5-6955-4c4b-8d04-62a81a6f15cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('submission.csv', index_col='id')\n",
    "\n",
    "submission['prediction'] = output_test.numpy()\n",
    "\n",
    "submission.to_csv('my_submission.csv', index_label='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d92c95c-f8fe-4147-8fea-699374947bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
